{
    "run": {
        "task": "classification",
        "lr_sched": "linear_warmup_cosine_lr",
        "init_lr": 0.0001,
        "min_lr": 0,
        "warmup_lr": 1e-08,
        "warmup_steps": 1000,
        "weight_decay": 0.05,
        "max_epoch": 20,
        "batch_size_train": 16,
        "batch_size_eval": 16,
        "num_workers": 0,
        "accum_grad_iters": 1,
        "max_len": 20,
        "max_new_tokens": 20,
        "min_len": 1,
        "min_new_tokens": 1,
        "num_beams": 5,
        "seed": 42,
        "output_dir": "output",
        "amp": true,
        "resume_ckpt_path": null,
        "evaluate": false,
        "train_splits": [
            "train"
        ],
        "valid_splits": [
            "val"
        ],
        "test_splits": [
            "test"
        ],
        "device": "cuda",
        "world_size": 1,
        "dist_url": "env://",
        "distributed": true,
        "report_metric": true,
        "suffix": null,
        "prefix": "train"
    },
    "model": {
        "arch": "blip2_vicuna_instruct",
        "load_finetuned": false,
        "load_pretrained": true,
        "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/InstructBLIP/instruct_blip_vicuna7b_trimmed.pth",
        "finetuned": "",
        "image_size": 224,
        "drop_path_rate": 0,
        "use_grad_checkpoint": false,
        "vit_precision": "fp16",
        "freeze_vit": true,
        "num_query_token": 32,
        "llm_model": "llm/vicuna-7b",
        "prompt": "",
        "memory_bank_length": 20,
        "num_frames": 100,
        "max_num_frames": 120,
        "model_type": "vicuna7b",
        "max_txt_len": 30
    },
    "preprocess": {
        "vis_processor": {
            "train": {
                "name": "blip2_video_train",
                "image_size": 224
            },
            "eval": {
                "name": "blip2_video_eval",
                "image_size": 224
            }
        },
        "text_processor": {
            "train": {
                "name": "blip_caption",
                "prompt": ""
            },
            "eval": {
                "name": "blip_caption",
                "prompt": ""
            }
        }
    },
    "datasets": {
        "breakfast_cls": {
            "data_type": "videos",
            "build_info": {
                "annotations": {
                    "train": {
                        "url": "breakfast/annotation/train.json",
                        "storage": "breakfast/annotation/train.json"
                    },
                    "val": {
                        "url": "breakfast/annotation/val.json",
                        "storage": "breakfast/annotation/val.json"
                    },
                    "test": {
                        "url": "breakfast/annotation/val.json",
                        "storage": "breakfast/annotation/val.json"
                    }
                },
                "videos": {
                    "storage": "breakfast/frames"
                }
            },
            "vis_processor": {
                "train": {
                    "name": "blip2_video_train",
                    "image_size": 224
                },
                "eval": {
                    "name": "blip2_video_eval",
                    "image_size": 224
                }
            },
            "text_processor": {
                "train": {
                    "name": "blip_caption",
                    "prompt": ""
                },
                "eval": {
                    "name": "blip_caption",
                    "prompt": ""
                }
            },
            "num_frames": 10
        }
    }
}